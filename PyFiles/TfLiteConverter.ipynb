{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TfLiteConverter.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V_1gfObPE3z"
      },
      "source": [
        "#Initial Setup\n",
        "\n",
        "!pip install tensorflow==1.14\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpOcquYrPaA2"
      },
      "source": [
        "import os\n",
        "import tempfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBUUuAkQPigq"
      },
      "source": [
        "\"\"\"To use the Kaggle API, sign up for a Kaggle account at https://www.kaggle.com.\n",
        " Then go to the 'Account' tab of your user profile (https://www.kaggle.com/account) and \n",
        " select 'Create API Token'. This will trigger the download of kaggle.json, a file containing your API credentials.\"\"\"\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"\" # TODO: enter your Kaggle user name here\n",
        "os.environ['KAGGLE_KEY'] = \"\" # TODO: enter your Kaggle key here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7rB8MvzPnYK"
      },
      "source": [
        "!kaggle datasets download -d t04glovern/ugatit-selfie2anime-pretrained\n",
        "!unzip -qq /content/ugatit-selfie2anime-pretrained.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpVJYDzDP0DP"
      },
      "source": [
        "!git clone https://github.com/taki0112/UGATIT\n",
        "%cd UGATIT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKnu2cM1P3I4"
      },
      "source": [
        "# Reference: https://dev.to/0xbf/use-dot-syntax-to-access-dictionary-key-python-tips-10ec\n",
        "class DictX(dict):\n",
        "    def __getattr__(self, key):\n",
        "        try:\n",
        "            return self[key]\n",
        "        except KeyError as k:\n",
        "            raise AttributeError(k)\n",
        "\n",
        "    def __setattr__(self, key, value):\n",
        "        self[key] = value\n",
        "\n",
        "    def __delattr__(self, key):\n",
        "        try:\n",
        "            del self[key]\n",
        "        except KeyError as k:\n",
        "            raise AttributeError(k)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '<DictX ' + dict.__repr__(self) + '>'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndYSf_SoP6uF"
      },
      "source": [
        "# This is needed just to initialize `UGATIT` class\n",
        "args = \tdict(phase='test',\n",
        "\tlight=True,\n",
        "\tdataset='selfie2anime',\n",
        "\tepoch=100,\n",
        "\titeration=10000,\n",
        "\tbatch_size=1,\n",
        "\tprint_freq=1000,\n",
        "\tsave_freq=1000,\n",
        "\tdecay_flag=True,\n",
        "\tdecay_epoch=50,\n",
        "\tlr=0.0001,\n",
        "\tGP_ld=10,\n",
        "\tadv_weight=1,\n",
        "\tcycle_weight=10,\n",
        "\tidentity_weight=10,\n",
        "\tcam_weight=1000,\n",
        "\tgan_type='lsgan',\n",
        "\tsmoothing=True,\n",
        "\tch=64,\n",
        "\tn_res=4,\n",
        "\tn_dis=6,\n",
        "\tn_critic=1,\n",
        "\tsn=True,\n",
        "\timg_size=256,\n",
        "\timg_ch=3,\n",
        "\taugment_flag=False,\n",
        "\tcheckpoint_dir='/content',\n",
        "\tresult_dir='/content',\n",
        "\tlog_dir='/content',\n",
        "\tsample_dir='/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoXXJq9DP-WM"
      },
      "source": [
        "\"\"\" Wrap the arguments in a dictionary because this particular format is required \n",
        "# in order to instantiate the `UGATIT` class\"\"\"\n",
        "data = DictX(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slqzp3N1QDQp"
      },
      "source": [
        "#@title\n",
        "from ops import *\n",
        "from utils import *\n",
        "from glob import glob\n",
        "import time\n",
        "from tensorflow.contrib.data import prefetch_to_device, shuffle_and_repeat, map_and_batch\n",
        "import numpy as np\n",
        "\n",
        "class UGATIT(object) :\n",
        "    def __init__(self, sess, args):\n",
        "        self.light = args.light\n",
        "\n",
        "        if self.light :\n",
        "            self.model_name = 'UGATIT_light'\n",
        "        else :\n",
        "            self.model_name = 'UGATIT'\n",
        "\n",
        "        self.sess = sess\n",
        "        self.phase = args.phase\n",
        "        self.checkpoint_dir = args.checkpoint_dir\n",
        "        self.result_dir = args.result_dir\n",
        "        self.log_dir = args.log_dir\n",
        "        self.dataset_name = args.dataset\n",
        "        self.augment_flag = args.augment_flag\n",
        "\n",
        "        self.epoch = args.epoch\n",
        "        self.iteration = args.iteration\n",
        "        self.decay_flag = args.decay_flag\n",
        "        self.decay_epoch = args.decay_epoch\n",
        "\n",
        "        self.gan_type = args.gan_type\n",
        "\n",
        "        self.batch_size = args.batch_size\n",
        "        self.print_freq = args.print_freq\n",
        "        self.save_freq = args.save_freq\n",
        "\n",
        "        self.init_lr = args.lr\n",
        "        self.ch = args.ch\n",
        "\n",
        "        \"\"\" Weight \"\"\"\n",
        "        self.adv_weight = args.adv_weight\n",
        "        self.cycle_weight = args.cycle_weight\n",
        "        self.identity_weight = args.identity_weight\n",
        "        self.cam_weight = args.cam_weight\n",
        "        self.ld = args.GP_ld\n",
        "        self.smoothing = args.smoothing\n",
        "\n",
        "        \"\"\" Generator \"\"\"\n",
        "        self.n_res = args.n_res\n",
        "\n",
        "        \"\"\" Discriminator \"\"\"\n",
        "        self.n_dis = args.n_dis\n",
        "        self.n_critic = args.n_critic\n",
        "        self.sn = args.sn\n",
        "\n",
        "        self.img_size = args.img_size\n",
        "        self.img_ch = args.img_ch\n",
        "\n",
        "\n",
        "        self.sample_dir = os.path.join(args.sample_dir, self.model_dir)\n",
        "        check_folder(self.sample_dir)\n",
        "\n",
        "        # self.trainA, self.trainB = prepare_data(dataset_name=self.dataset_name, size=self.img_size\n",
        "        self.trainA_dataset = glob('./dataset/{}/*.*'.format(self.dataset_name + '/trainA'))\n",
        "        self.trainB_dataset = glob('./dataset/{}/*.*'.format(self.dataset_name + '/trainB'))\n",
        "        self.dataset_num = max(len(self.trainA_dataset), len(self.trainB_dataset))\n",
        "\n",
        "        print()\n",
        "\n",
        "        print(\"##### Information #####\")\n",
        "        print(\"# light : \", self.light)\n",
        "        print(\"# gan type : \", self.gan_type)\n",
        "        print(\"# dataset : \", self.dataset_name)\n",
        "        print(\"# max dataset number : \", self.dataset_num)\n",
        "        print(\"# batch_size : \", self.batch_size)\n",
        "        print(\"# epoch : \", self.epoch)\n",
        "        print(\"# iteration per epoch : \", self.iteration)\n",
        "        print(\"# smoothing : \", self.smoothing)\n",
        "\n",
        "        print()\n",
        "\n",
        "        print(\"##### Generator #####\")\n",
        "        print(\"# residual blocks : \", self.n_res)\n",
        "\n",
        "        print()\n",
        "\n",
        "        print(\"##### Discriminator #####\")\n",
        "        print(\"# discriminator layer : \", self.n_dis)\n",
        "        print(\"# the number of critic : \", self.n_critic)\n",
        "        print(\"# spectral normalization : \", self.sn)\n",
        "\n",
        "        print()\n",
        "\n",
        "        print(\"##### Weight #####\")\n",
        "        print(\"# adv_weight : \", self.adv_weight)\n",
        "        print(\"# cycle_weight : \", self.cycle_weight)\n",
        "        print(\"# identity_weight : \", self.identity_weight)\n",
        "        print(\"# cam_weight : \", self.cam_weight)\n",
        "\n",
        "    ##################################################################################\n",
        "    # Generator\n",
        "    ##################################################################################\n",
        "\n",
        "    def generator(self, x_init, reuse=False, scope=\"generator\"):\n",
        "        channel = self.ch\n",
        "        with tf.variable_scope(scope, reuse=reuse) :\n",
        "            x = conv(x_init, channel, kernel=7, stride=1, pad=3, pad_type='reflect', scope='conv')\n",
        "            x = instance_norm(x, scope='ins_norm')\n",
        "            x = relu(x)\n",
        "\n",
        "            # Down-Sampling\n",
        "            for i in range(2) :\n",
        "                x = conv(x, channel*2, kernel=3, stride=2, pad=1, pad_type='reflect', scope='conv_'+str(i))\n",
        "                x = instance_norm(x, scope='ins_norm_'+str(i))\n",
        "                x = relu(x)\n",
        "\n",
        "                channel = channel * 2\n",
        "\n",
        "            # Down-Sampling Bottleneck\n",
        "            for i in range(self.n_res):\n",
        "                x = resblock(x, channel, scope='resblock_' + str(i))\n",
        "\n",
        "\n",
        "            # Class Activation Map\n",
        "            cam_x = global_avg_pooling(x)\n",
        "            cam_gap_logit, cam_x_weight = fully_connected_with_w(cam_x, scope='CAM_logit')\n",
        "            x_gap = tf.multiply(x, cam_x_weight)\n",
        "\n",
        "            cam_x = global_max_pooling(x)\n",
        "            cam_gmp_logit, cam_x_weight = fully_connected_with_w(cam_x, reuse=True, scope='CAM_logit')\n",
        "            x_gmp = tf.multiply(x, cam_x_weight)\n",
        "\n",
        "\n",
        "            cam_logit = tf.concat([cam_gap_logit, cam_gmp_logit], axis=-1)\n",
        "            x = tf.concat([x_gap, x_gmp], axis=-1)\n",
        "\n",
        "            x = conv(x, channel, kernel=1, stride=1, scope='conv_1x1')\n",
        "            x = relu(x)\n",
        "\n",
        "            heatmap = tf.squeeze(tf.reduce_sum(x, axis=-1))\n",
        "\n",
        "            # Gamma, Beta block\n",
        "            gamma, beta = self.MLP(x, reuse=reuse)\n",
        "\n",
        "            # Up-Sampling Bottleneck\n",
        "            for i in range(self.n_res):\n",
        "                x = adaptive_ins_layer_resblock(x, channel, gamma, beta, smoothing=self.smoothing, scope='adaptive_resblock' + str(i))\n",
        "\n",
        "            # Up-Sampling\n",
        "            for i in range(2) :\n",
        "                x = up_sample(x, scale_factor=2)\n",
        "                x = conv(x, channel//2, kernel=3, stride=1, pad=1, pad_type='reflect', scope='up_conv_'+str(i))\n",
        "                x = layer_instance_norm(x, scope='layer_ins_norm_'+str(i))\n",
        "                x = relu(x)\n",
        "\n",
        "                channel = channel // 2\n",
        "\n",
        "\n",
        "            x = conv(x, channels=3, kernel=7, stride=1, pad=3, pad_type='reflect', scope='G_logit')\n",
        "            x = tanh(x)\n",
        "\n",
        "            return x, cam_logit, heatmap\n",
        "\n",
        "    def MLP(self, x, use_bias=True, reuse=False, scope='MLP'):\n",
        "        channel = self.ch * self.n_res\n",
        "\n",
        "        if self.light :\n",
        "            x = global_avg_pooling(x)\n",
        "\n",
        "        with tf.variable_scope(scope, reuse=reuse):\n",
        "            for i in range(2) :\n",
        "                x = fully_connected(x, channel, use_bias, scope='linear_' + str(i))\n",
        "                x = relu(x)\n",
        "\n",
        "\n",
        "            gamma = fully_connected(x, channel, use_bias, scope='gamma')\n",
        "            beta = fully_connected(x, channel, use_bias, scope='beta')\n",
        "\n",
        "            gamma = tf.reshape(gamma, shape=[self.batch_size, 1, 1, channel])\n",
        "            beta = tf.reshape(beta, shape=[self.batch_size, 1, 1, channel])\n",
        "\n",
        "            return gamma, beta\n",
        "\n",
        "    ##################################################################################\n",
        "    # Discriminator\n",
        "    ##################################################################################\n",
        "\n",
        "    def discriminator(self, x_init, reuse=False, scope=\"discriminator\"):\n",
        "        D_logit = []\n",
        "        D_CAM_logit = []\n",
        "        with tf.variable_scope(scope, reuse=reuse) :\n",
        "            local_x, local_cam, local_heatmap = self.discriminator_local(x_init, reuse=reuse, scope='local')\n",
        "            global_x, global_cam, global_heatmap = self.discriminator_global(x_init, reuse=reuse, scope='global')\n",
        "\n",
        "            D_logit.extend([local_x, global_x])\n",
        "            D_CAM_logit.extend([local_cam, global_cam])\n",
        "\n",
        "            return D_logit, D_CAM_logit, local_heatmap, global_heatmap\n",
        "\n",
        "    def discriminator_global(self, x_init, reuse=False, scope='discriminator_global'):\n",
        "        with tf.variable_scope(scope, reuse=reuse):\n",
        "            channel = self.ch\n",
        "            x = conv(x_init, channel, kernel=4, stride=2, pad=1, pad_type='reflect', sn=self.sn, scope='conv_0')\n",
        "            x = lrelu(x, 0.2)\n",
        "\n",
        "            for i in range(1, self.n_dis - 1):\n",
        "                x = conv(x, channel * 2, kernel=4, stride=2, pad=1, pad_type='reflect', sn=self.sn, scope='conv_' + str(i))\n",
        "                x = lrelu(x, 0.2)\n",
        "\n",
        "                channel = channel * 2\n",
        "\n",
        "            x = conv(x, channel * 2, kernel=4, stride=1, pad=1, pad_type='reflect', sn=self.sn, scope='conv_last')\n",
        "            x = lrelu(x, 0.2)\n",
        "\n",
        "            channel = channel * 2\n",
        "\n",
        "            cam_x = global_avg_pooling(x)\n",
        "            cam_gap_logit, cam_x_weight = fully_connected_with_w(cam_x, sn=self.sn, scope='CAM_logit')\n",
        "            x_gap = tf.multiply(x, cam_x_weight)\n",
        "\n",
        "            cam_x = global_max_pooling(x)\n",
        "            cam_gmp_logit, cam_x_weight = fully_connected_with_w(cam_x, sn=self.sn, reuse=True, scope='CAM_logit')\n",
        "            x_gmp = tf.multiply(x, cam_x_weight)\n",
        "\n",
        "            cam_logit = tf.concat([cam_gap_logit, cam_gmp_logit], axis=-1)\n",
        "            x = tf.concat([x_gap, x_gmp], axis=-1)\n",
        "\n",
        "            x = conv(x, channel, kernel=1, stride=1, scope='conv_1x1')\n",
        "            x = lrelu(x, 0.2)\n",
        "\n",
        "            heatmap = tf.squeeze(tf.reduce_sum(x, axis=-1))\n",
        "\n",
        "\n",
        "            x = conv(x, channels=1, kernel=4, stride=1, pad=1, pad_type='reflect', sn=self.sn, scope='D_logit')\n",
        "\n",
        "            return x, cam_logit, heatmap\n",
        "\n",
        "    def discriminator_local(self, x_init, reuse=False, scope='discriminator_local'):\n",
        "        with tf.variable_scope(scope, reuse=reuse) :\n",
        "            channel = self.ch\n",
        "            x = conv(x_init, channel, kernel=4, stride=2, pad=1, pad_type='reflect', sn=self.sn, scope='conv_0')\n",
        "            x = lrelu(x, 0.2)\n",
        "\n",
        "            for i in range(1, self.n_dis - 2 - 1):\n",
        "                x = conv(x, channel * 2, kernel=4, stride=2, pad=1, pad_type='reflect', sn=self.sn, scope='conv_' + str(i))\n",
        "                x = lrelu(x, 0.2)\n",
        "\n",
        "                channel = channel * 2\n",
        "\n",
        "            x = conv(x, channel * 2, kernel=4, stride=1, pad=1, pad_type='reflect', sn=self.sn, scope='conv_last')\n",
        "            x = lrelu(x, 0.2)\n",
        "\n",
        "            channel = channel * 2\n",
        "\n",
        "            cam_x = global_avg_pooling(x)\n",
        "            cam_gap_logit, cam_x_weight = fully_connected_with_w(cam_x, sn=self.sn, scope='CAM_logit')\n",
        "            x_gap = tf.multiply(x, cam_x_weight)\n",
        "\n",
        "            cam_x = global_max_pooling(x)\n",
        "            cam_gmp_logit, cam_x_weight = fully_connected_with_w(cam_x, sn=self.sn, reuse=True, scope='CAM_logit')\n",
        "            x_gmp = tf.multiply(x, cam_x_weight)\n",
        "\n",
        "            cam_logit = tf.concat([cam_gap_logit, cam_gmp_logit], axis=-1)\n",
        "            x = tf.concat([x_gap, x_gmp], axis=-1)\n",
        "\n",
        "            x = conv(x, channel, kernel=1, stride=1, scope='conv_1x1')\n",
        "            x = lrelu(x, 0.2)\n",
        "\n",
        "            heatmap = tf.squeeze(tf.reduce_sum(x, axis=-1))\n",
        "\n",
        "            x = conv(x, channels=1, kernel=4, stride=1, pad=1, pad_type='reflect', sn=self.sn, scope='D_logit')\n",
        "\n",
        "            return x, cam_logit, heatmap\n",
        "\n",
        "    ##################################################################################\n",
        "    # Model\n",
        "    ##################################################################################\n",
        "\n",
        "    def generate_a2b(self, x_A, reuse=False):\n",
        "        out, cam, _ = self.generator(x_A, reuse=reuse, scope=\"generator_B\")\n",
        "\n",
        "        return out, cam\n",
        "\n",
        "    def generate_b2a(self, x_B, reuse=False):\n",
        "        out, cam, _ = self.generator(x_B, reuse=reuse, scope=\"generator_A\")\n",
        "\n",
        "        return out, cam\n",
        "\n",
        "    def discriminate_real(self, x_A, x_B):\n",
        "        real_A_logit, real_A_cam_logit, _, _ = self.discriminator(x_A, scope=\"discriminator_A\")\n",
        "        real_B_logit, real_B_cam_logit, _, _ = self.discriminator(x_B, scope=\"discriminator_B\")\n",
        "\n",
        "        return real_A_logit, real_A_cam_logit, real_B_logit, real_B_cam_logit\n",
        "\n",
        "    def discriminate_fake(self, x_ba, x_ab):\n",
        "        fake_A_logit, fake_A_cam_logit, _, _ = self.discriminator(x_ba, reuse=True, scope=\"discriminator_A\")\n",
        "        fake_B_logit, fake_B_cam_logit, _, _ = self.discriminator(x_ab, reuse=True, scope=\"discriminator_B\")\n",
        "\n",
        "        return fake_A_logit, fake_A_cam_logit, fake_B_logit, fake_B_cam_logit\n",
        "\n",
        "    def gradient_panalty(self, real, fake, scope=\"discriminator_A\"):\n",
        "        if self.gan_type.__contains__('dragan'):\n",
        "            eps = tf.random_uniform(shape=tf.shape(real), minval=0., maxval=1.)\n",
        "            _, x_var = tf.nn.moments(real, axes=[0, 1, 2, 3])\n",
        "            x_std = tf.sqrt(x_var)  # magnitude of noise decides the size of local region\n",
        "\n",
        "            fake = real + 0.5 * x_std * eps\n",
        "\n",
        "        alpha = tf.random_uniform(shape=[self.batch_size, 1, 1, 1], minval=0., maxval=1.)\n",
        "        interpolated = real + alpha * (fake - real)\n",
        "\n",
        "        logit, cam_logit, _, _ = self.discriminator(interpolated, reuse=True, scope=scope)\n",
        "\n",
        "\n",
        "        GP = []\n",
        "        cam_GP = []\n",
        "\n",
        "        for i in range(2) :\n",
        "            grad = tf.gradients(logit[i], interpolated)[0] # gradient of D(interpolated)\n",
        "            grad_norm = tf.norm(flatten(grad), axis=1) # l2 norm\n",
        "\n",
        "            # WGAN - LP\n",
        "            if self.gan_type == 'wgan-lp' :\n",
        "                GP.append(self.ld * tf.reduce_mean(tf.square(tf.maximum(0.0, grad_norm - 1.))))\n",
        "\n",
        "            elif self.gan_type == 'wgan-gp' or self.gan_type == 'dragan':\n",
        "                GP.append(self.ld * tf.reduce_mean(tf.square(grad_norm - 1.)))\n",
        "\n",
        "        for i in range(2) :\n",
        "            grad = tf.gradients(cam_logit[i], interpolated)[0] # gradient of D(interpolated)\n",
        "            grad_norm = tf.norm(flatten(grad), axis=1) # l2 norm\n",
        "\n",
        "            # WGAN - LP\n",
        "            if self.gan_type == 'wgan-lp' :\n",
        "                cam_GP.append(self.ld * tf.reduce_mean(tf.square(tf.maximum(0.0, grad_norm - 1.))))\n",
        "\n",
        "            elif self.gan_type == 'wgan-gp' or self.gan_type == 'dragan':\n",
        "                cam_GP.append(self.ld * tf.reduce_mean(tf.square(grad_norm - 1.)))\n",
        "\n",
        "\n",
        "        return sum(GP), sum(cam_GP)\n",
        "\n",
        "    def build_model(self):\n",
        "        if self.phase == 'train' :\n",
        "            self.lr = tf.placeholder(tf.float32, name='learning_rate')\n",
        "\n",
        "\n",
        "            \"\"\" Input Image\"\"\"\n",
        "            Image_Data_Class = ImageData(self.img_size, self.img_ch, self.augment_flag)\n",
        "\n",
        "            trainA = tf.data.Dataset.from_tensor_slices(self.trainA_dataset)\n",
        "            trainB = tf.data.Dataset.from_tensor_slices(self.trainB_dataset)\n",
        "\n",
        "\n",
        "            gpu_device = '/gpu:0'\n",
        "            trainA = trainA.apply(shuffle_and_repeat(self.dataset_num)).apply(map_and_batch(Image_Data_Class.image_processing, self.batch_size, num_parallel_batches=16, drop_remainder=True)).apply(prefetch_to_device(gpu_device, None))\n",
        "            trainB = trainB.apply(shuffle_and_repeat(self.dataset_num)).apply(map_and_batch(Image_Data_Class.image_processing, self.batch_size, num_parallel_batches=16, drop_remainder=True)).apply(prefetch_to_device(gpu_device, None))\n",
        "\n",
        "\n",
        "            trainA_iterator = trainA.make_one_shot_iterator()\n",
        "            trainB_iterator = trainB.make_one_shot_iterator()\n",
        "\n",
        "            self.domain_A = trainA_iterator.get_next()\n",
        "            self.domain_B = trainB_iterator.get_next()\n",
        "\n",
        "            \"\"\" Define Generator, Discriminator \"\"\"\n",
        "            x_ab, cam_ab = self.generate_a2b(self.domain_A) # real a\n",
        "            x_ba, cam_ba = self.generate_b2a(self.domain_B) # real b\n",
        "\n",
        "            x_aba, _ = self.generate_b2a(x_ab, reuse=True) # real b\n",
        "            x_bab, _ = self.generate_a2b(x_ba, reuse=True) # real a\n",
        "\n",
        "            x_aa, cam_aa = self.generate_b2a(self.domain_A, reuse=True) # fake b\n",
        "            x_bb, cam_bb = self.generate_a2b(self.domain_B, reuse=True) # fake a\n",
        "\n",
        "            real_A_logit, real_A_cam_logit, real_B_logit, real_B_cam_logit = self.discriminate_real(self.domain_A, self.domain_B)\n",
        "            fake_A_logit, fake_A_cam_logit, fake_B_logit, fake_B_cam_logit = self.discriminate_fake(x_ba, x_ab)\n",
        "\n",
        "\n",
        "            \"\"\" Define Loss \"\"\"\n",
        "            if self.gan_type.__contains__('wgan') or self.gan_type == 'dragan' :\n",
        "                GP_A, GP_CAM_A = self.gradient_panalty(real=self.domain_A, fake=x_ba, scope=\"discriminator_A\")\n",
        "                GP_B, GP_CAM_B = self.gradient_panalty(real=self.domain_B, fake=x_ab, scope=\"discriminator_B\")\n",
        "            else :\n",
        "                GP_A, GP_CAM_A  = 0, 0\n",
        "                GP_B, GP_CAM_B = 0, 0\n",
        "\n",
        "            G_ad_loss_A = (generator_loss(self.gan_type, fake_A_logit) + generator_loss(self.gan_type, fake_A_cam_logit))\n",
        "            G_ad_loss_B = (generator_loss(self.gan_type, fake_B_logit) + generator_loss(self.gan_type, fake_B_cam_logit))\n",
        "\n",
        "            D_ad_loss_A = (discriminator_loss(self.gan_type, real_A_logit, fake_A_logit) + discriminator_loss(self.gan_type, real_A_cam_logit, fake_A_cam_logit) + GP_A + GP_CAM_A)\n",
        "            D_ad_loss_B = (discriminator_loss(self.gan_type, real_B_logit, fake_B_logit) + discriminator_loss(self.gan_type, real_B_cam_logit, fake_B_cam_logit) + GP_B + GP_CAM_B)\n",
        "\n",
        "            reconstruction_A = L1_loss(x_aba, self.domain_A) # reconstruction\n",
        "            reconstruction_B = L1_loss(x_bab, self.domain_B) # reconstruction\n",
        "\n",
        "            identity_A = L1_loss(x_aa, self.domain_A)\n",
        "            identity_B = L1_loss(x_bb, self.domain_B)\n",
        "\n",
        "            cam_A = cam_loss(source=cam_ba, non_source=cam_aa)\n",
        "            cam_B = cam_loss(source=cam_ab, non_source=cam_bb)\n",
        "\n",
        "            Generator_A_gan = self.adv_weight * G_ad_loss_A\n",
        "            Generator_A_cycle = self.cycle_weight * reconstruction_B\n",
        "            Generator_A_identity = self.identity_weight * identity_A\n",
        "            Generator_A_cam = self.cam_weight * cam_A\n",
        "\n",
        "\n",
        "            Generator_B_gan = self.adv_weight * G_ad_loss_B\n",
        "            Generator_B_cycle = self.cycle_weight * reconstruction_A\n",
        "            Generator_B_identity = self.identity_weight * identity_B\n",
        "            Generator_B_cam = self.cam_weight * cam_B\n",
        "\n",
        "\n",
        "            Generator_A_loss = Generator_A_gan + Generator_A_cycle + Generator_A_identity + Generator_A_cam\n",
        "            Generator_B_loss = Generator_B_gan + Generator_B_cycle + Generator_B_identity + Generator_B_cam\n",
        "\n",
        "\n",
        "            Discriminator_A_loss = self.adv_weight * D_ad_loss_A\n",
        "            Discriminator_B_loss = self.adv_weight * D_ad_loss_B\n",
        "\n",
        "            self.Generator_loss = Generator_A_loss + Generator_B_loss + regularization_loss('generator')\n",
        "            self.Discriminator_loss = Discriminator_A_loss + Discriminator_B_loss + regularization_loss('discriminator')\n",
        "\n",
        "\n",
        "            \"\"\" Result Image \"\"\"\n",
        "            self.fake_A = x_ba\n",
        "            self.fake_B = x_ab\n",
        "\n",
        "            self.real_A = self.domain_A\n",
        "            self.real_B = self.domain_B\n",
        "\n",
        "\n",
        "            \"\"\" Training \"\"\"\n",
        "            t_vars = tf.trainable_variables()\n",
        "            G_vars = [var for var in t_vars if 'generator' in var.name]\n",
        "            D_vars = [var for var in t_vars if 'discriminator' in var.name]\n",
        "\n",
        "            self.G_optim = tf.train.AdamOptimizer(self.lr, beta1=0.5, beta2=0.999).minimize(self.Generator_loss, var_list=G_vars)\n",
        "            self.D_optim = tf.train.AdamOptimizer(self.lr, beta1=0.5, beta2=0.999).minimize(self.Discriminator_loss, var_list=D_vars)\n",
        "\n",
        "\n",
        "            \"\"\"\" Summary \"\"\"\n",
        "            self.all_G_loss = tf.summary.scalar(\"Generator_loss\", self.Generator_loss)\n",
        "            self.all_D_loss = tf.summary.scalar(\"Discriminator_loss\", self.Discriminator_loss)\n",
        "\n",
        "            self.G_A_loss = tf.summary.scalar(\"G_A_loss\", Generator_A_loss)\n",
        "            self.G_A_gan = tf.summary.scalar(\"G_A_gan\", Generator_A_gan)\n",
        "            self.G_A_cycle = tf.summary.scalar(\"G_A_cycle\", Generator_A_cycle)\n",
        "            self.G_A_identity = tf.summary.scalar(\"G_A_identity\", Generator_A_identity)\n",
        "            self.G_A_cam = tf.summary.scalar(\"G_A_cam\", Generator_A_cam)\n",
        "\n",
        "            self.G_B_loss = tf.summary.scalar(\"G_B_loss\", Generator_B_loss)\n",
        "            self.G_B_gan = tf.summary.scalar(\"G_B_gan\", Generator_B_gan)\n",
        "            self.G_B_cycle = tf.summary.scalar(\"G_B_cycle\", Generator_B_cycle)\n",
        "            self.G_B_identity = tf.summary.scalar(\"G_B_identity\", Generator_B_identity)\n",
        "            self.G_B_cam = tf.summary.scalar(\"G_B_cam\", Generator_B_cam)\n",
        "\n",
        "            self.D_A_loss = tf.summary.scalar(\"D_A_loss\", Discriminator_A_loss)\n",
        "            self.D_B_loss = tf.summary.scalar(\"D_B_loss\", Discriminator_B_loss)\n",
        "\n",
        "            self.rho_var = []\n",
        "            for var in tf.trainable_variables():\n",
        "                if 'rho' in var.name:\n",
        "                    self.rho_var.append(tf.summary.histogram(var.name, var))\n",
        "                    self.rho_var.append(tf.summary.scalar(var.name + \"_min\", tf.reduce_min(var)))\n",
        "                    self.rho_var.append(tf.summary.scalar(var.name + \"_max\", tf.reduce_max(var)))\n",
        "                    self.rho_var.append(tf.summary.scalar(var.name + \"_mean\", tf.reduce_mean(var)))\n",
        "\n",
        "            g_summary_list = [self.G_A_loss, self.G_A_gan, self.G_A_cycle, self.G_A_identity, self.G_A_cam,\n",
        "                              self.G_B_loss, self.G_B_gan, self.G_B_cycle, self.G_B_identity, self.G_B_cam,\n",
        "                              self.all_G_loss]\n",
        "\n",
        "            g_summary_list.extend(self.rho_var)\n",
        "            d_summary_list = [self.D_A_loss, self.D_B_loss, self.all_D_loss]\n",
        "\n",
        "            self.G_loss = tf.summary.merge(g_summary_list)\n",
        "            self.D_loss = tf.summary.merge(d_summary_list)\n",
        "\n",
        "        else :\n",
        "            \"\"\" Test \"\"\"\n",
        "            self.test_domain_A = tf.placeholder(tf.float32, [1, self.img_size, self.img_size, self.img_ch], name='test_domain_A')\n",
        "            self.test_domain_B = tf.placeholder(tf.float32, [1, self.img_size, self.img_size, self.img_ch], name='test_domain_B')\n",
        "\n",
        "\n",
        "            self.test_fake_B, _ = self.generate_a2b(self.test_domain_A)\n",
        "            self.test_fake_A, _ = self.generate_b2a(self.test_domain_B)\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        # initialize all variables\n",
        "        tf.global_variables_initializer().run()\n",
        "\n",
        "        # saver to save model\n",
        "        self.saver = tf.train.Saver()\n",
        "\n",
        "        # summary writer\n",
        "        self.writer = tf.summary.FileWriter(self.log_dir + '/' + self.model_dir, self.sess.graph)\n",
        "\n",
        "\n",
        "        # restore check-point if it exits\n",
        "        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n",
        "        if could_load:\n",
        "            start_epoch = (int)(checkpoint_counter / self.iteration)\n",
        "            start_batch_id = checkpoint_counter - start_epoch * self.iteration\n",
        "            counter = checkpoint_counter\n",
        "            print(\" [*] Load SUCCESS\")\n",
        "        else:\n",
        "            start_epoch = 0\n",
        "            start_batch_id = 0\n",
        "            counter = 1\n",
        "            print(\" [!] Load failed...\")\n",
        "\n",
        "        # loop for epoch\n",
        "        start_time = time.time()\n",
        "        past_g_loss = -1.\n",
        "        lr = self.init_lr\n",
        "        for epoch in range(start_epoch, self.epoch):\n",
        "            # lr = self.init_lr if epoch < self.decay_epoch else self.init_lr * (self.epoch - epoch) / (self.epoch - self.decay_epoch)\n",
        "            if self.decay_flag :\n",
        "                #lr = self.init_lr * pow(0.5, epoch // self.decay_epoch)\n",
        "                lr = self.init_lr if epoch < self.decay_epoch else self.init_lr * (self.epoch - epoch) / (self.epoch - self.decay_epoch)\n",
        "            for idx in range(start_batch_id, self.iteration):\n",
        "                train_feed_dict = {\n",
        "                    self.lr : lr\n",
        "                }\n",
        "\n",
        "                # Update D\n",
        "                _, d_loss, summary_str = self.sess.run([self.D_optim,\n",
        "                                                        self.Discriminator_loss, self.D_loss], feed_dict = train_feed_dict)\n",
        "                self.writer.add_summary(summary_str, counter)\n",
        "\n",
        "                # Update G\n",
        "                g_loss = None\n",
        "                if (counter - 1) % self.n_critic == 0 :\n",
        "                    batch_A_images, batch_B_images, fake_A, fake_B, _, g_loss, summary_str = self.sess.run([self.real_A, self.real_B,\n",
        "                                                                                                            self.fake_A, self.fake_B,\n",
        "                                                                                                            self.G_optim,\n",
        "                                                                                                            self.Generator_loss, self.G_loss], feed_dict = train_feed_dict)\n",
        "                    self.writer.add_summary(summary_str, counter)\n",
        "                    past_g_loss = g_loss\n",
        "\n",
        "                # display training status\n",
        "                counter += 1\n",
        "                if g_loss == None :\n",
        "                    g_loss = past_g_loss\n",
        "                print(\"Epoch: [%2d] [%5d/%5d] time: %4.4f d_loss: %.8f, g_loss: %.8f\" % (epoch, idx, self.iteration, time.time() - start_time, d_loss, g_loss))\n",
        "\n",
        "                if np.mod(idx+1, self.print_freq) == 0 :\n",
        "                    save_images(batch_A_images, [self.batch_size, 1],\n",
        "                                './{}/real_A_{:03d}_{:05d}.png'.format(self.sample_dir, epoch, idx+1))\n",
        "                    # save_images(batch_B_images, [self.batch_size, 1],\n",
        "                    #             './{}/real_B_{:03d}_{:05d}.png'.format(self.sample_dir, epoch, idx+1))\n",
        "\n",
        "                    # save_images(fake_A, [self.batch_size, 1],\n",
        "                    #             './{}/fake_A_{:03d}_{:05d}.png'.format(self.sample_dir, epoch, idx+1))\n",
        "                    save_images(fake_B, [self.batch_size, 1],\n",
        "                                './{}/fake_B_{:03d}_{:05d}.png'.format(self.sample_dir, epoch, idx+1))\n",
        "\n",
        "                if np.mod(idx + 1, self.save_freq) == 0:\n",
        "                    self.save(self.checkpoint_dir, counter)\n",
        "\n",
        "\n",
        "\n",
        "            # After an epoch, start_batch_id is set to zero\n",
        "            # non-zero value is only for the first epoch after loading pre-trained model\n",
        "            start_batch_id = 0\n",
        "\n",
        "            # save model for final step\n",
        "            self.save(self.checkpoint_dir, counter)\n",
        "\n",
        "    @property\n",
        "    def model_dir(self):\n",
        "        n_res = str(self.n_res) + 'resblock'\n",
        "        n_dis = str(self.n_dis) + 'dis'\n",
        "\n",
        "        if self.smoothing :\n",
        "            smoothing = '_smoothing'\n",
        "        else :\n",
        "            smoothing = ''\n",
        "\n",
        "        if self.sn :\n",
        "            sn = '_sn'\n",
        "        else :\n",
        "            sn = ''\n",
        "\n",
        "        return \"{}_{}_{}_{}_{}_{}_{}_{}_{}_{}{}{}\".format(self.model_name, self.dataset_name,\n",
        "                                                         self.gan_type, n_res, n_dis,\n",
        "                                                         self.n_critic,\n",
        "                                                         self.adv_weight, self.cycle_weight, self.identity_weight, self.cam_weight, sn, smoothing)\n",
        "\n",
        "    def save(self, checkpoint_dir, step):\n",
        "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir)\n",
        "\n",
        "        if not os.path.exists(checkpoint_dir):\n",
        "            os.makedirs(checkpoint_dir)\n",
        "\n",
        "        self.saver.save(self.sess, os.path.join(checkpoint_dir, self.model_name + '.model'), global_step=step)\n",
        "\n",
        "    def load(self, checkpoint_dir):\n",
        "        print(\" [*] Reading checkpoints...\")\n",
        "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir)\n",
        "\n",
        "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
        "        if ckpt and ckpt.model_checkpoint_path:\n",
        "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
        "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
        "            counter = int(ckpt_name.split('-')[-1])\n",
        "            print(\" [*] Success to read {}\".format(ckpt_name))\n",
        "            return True, counter\n",
        "        else:\n",
        "            print(\" [*] Failed to find a checkpoint\")\n",
        "            return False, 0\n",
        "\n",
        "    def test(self):\n",
        "        tf.global_variables_initializer().run()\n",
        "        test_A_files = glob('./dataset/{}/*.*'.format(self.dataset_name + '/testA'))\n",
        "        test_B_files = glob('./dataset/{}/*.*'.format(self.dataset_name + '/testB'))\n",
        "\n",
        "        self.saver = tf.train.Saver()\n",
        "        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n",
        "        self.result_dir = os.path.join(self.result_dir, self.model_dir)\n",
        "        check_folder(self.result_dir)\n",
        "\n",
        "        if could_load :\n",
        "            print(\" [*] Load SUCCESS\")\n",
        "        else :\n",
        "            print(\" [!] Load failed...\")\n",
        "\n",
        "        # write html for visual comparison\n",
        "        index_path = os.path.join(self.result_dir, 'index.html')\n",
        "        index = open(index_path, 'w')\n",
        "        index.write(\"<html><body><table><tr>\")\n",
        "        index.write(\"<th>name</th><th>input</th><th>output</th></tr>\")\n",
        "\n",
        "        for sample_file  in test_A_files : # A -> B\n",
        "            print('Processing A image: ' + sample_file)\n",
        "            sample_image = np.asarray(load_test_data(sample_file, size=self.img_size))\n",
        "            image_path = os.path.join(self.result_dir,'{0}'.format(os.path.basename(sample_file)))\n",
        "\n",
        "            fake_img = self.sess.run(self.test_fake_B, feed_dict = {self.test_domain_A : sample_image})\n",
        "            save_images(fake_img, [1, 1], image_path)\n",
        "\n",
        "            index.write(\"<td>%s</td>\" % os.path.basename(image_path))\n",
        "\n",
        "            index.write(\"<td><img src='%s' width='%d' height='%d'></td>\" % (sample_file if os.path.isabs(sample_file) else (\n",
        "                '../..' + os.path.sep + sample_file), self.img_size, self.img_size))\n",
        "            index.write(\"<td><img src='%s' width='%d' height='%d'></td>\" % (image_path if os.path.isabs(image_path) else (\n",
        "                '../..' + os.path.sep + image_path), self.img_size, self.img_size))\n",
        "            index.write(\"</tr>\")\n",
        "\n",
        "        for sample_file  in test_B_files : # B -> A\n",
        "            print('Processing B image: ' + sample_file)\n",
        "            sample_image = np.asarray(load_test_data(sample_file, size=self.img_size))\n",
        "            image_path = os.path.join(self.result_dir,'{0}'.format(os.path.basename(sample_file)))\n",
        "\n",
        "            fake_img = self.sess.run(self.test_fake_A, feed_dict = {self.test_domain_B : sample_image})\n",
        "\n",
        "            save_images(fake_img, [1, 1], image_path)\n",
        "            index.write(\"<td>%s</td>\" % os.path.basename(image_path))\n",
        "            index.write(\"<td><img src='%s' width='%d' height='%d'></td>\" % (sample_file if os.path.isabs(sample_file) else (\n",
        "                    '../..' + os.path.sep + sample_file), self.img_size, self.img_size))\n",
        "            index.write(\"<td><img src='%s' width='%d' height='%d'></td>\" % (image_path if os.path.isabs(image_path) else (\n",
        "                    '../..' + os.path.sep + image_path), self.img_size, self.img_size))\n",
        "            index.write(\"</tr>\")\n",
        "        index.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kwon2KGQted"
      },
      "source": [
        "#BUILD AND INITIALIZE THE MODEL\n",
        "\n",
        "def load_checkpoint(sess, checkpoint):\n",
        "  \"\"\"Loads a checkpoint file into the session.\n",
        "  Args:\n",
        "    sess: tf.Session, the TF session to load variables from the checkpoint to.\n",
        "    checkpoint: str, path to the checkpoint file.\n",
        "  \"\"\"\n",
        "  model_saver = tf.train.Saver(tf.global_variables())\n",
        "  checkpoint = os.path.expanduser(checkpoint)\n",
        "  if tf.gfile.IsDirectory(checkpoint):\n",
        "    checkpoint = tf.train.latest_checkpoint(checkpoint)\n",
        "    tf.logging.info('loading latest checkpoint file: {}'.format(checkpoint))\n",
        "  model_saver.restore(sess, checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrfbTMSqQ1g-"
      },
      "source": [
        "#EXPORTING TO SavedModel\n",
        "\n",
        "saved_model_dir = tempfile.mkdtemp()\n",
        "\n",
        "with tf.Graph().as_default(), tf.Session() as sess:\n",
        "    gan = UGATIT(sess, data)\n",
        "    gan.build_model()\n",
        "    load_checkpoint(sess, '/content/checkpoint/UGATIT_light_selfie2anime_lsgan_4resblock_6dis_1_1_10_10_1000_sn_smoothing')\n",
        "    \n",
        "    # Write SavedModel for serving or conversion to TF Lite\n",
        "    tf.saved_model.simple_save(\n",
        "        sess,\n",
        "        saved_model_dir,\n",
        "        inputs={\n",
        "            gan.test_domain_A.name: gan.test_domain_A,\n",
        "        },\n",
        "        outputs={gan.test_fake_B.name: gan.test_fake_B})\n",
        "    tf.logging.debug('Export transform SavedModel to',\n",
        "                     saved_model_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByrB_LEaRDOY"
      },
      "source": [
        "!pip install -q tensorflow==2.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-OHZ_lDRZ2Q"
      },
      "source": [
        "#TfLite CONVERSION\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def convert_to_tflite(saved_model_path, tflite_model_path):\n",
        "    model = tf.saved_model.load(saved_model_path)\n",
        "    concrete_func = model.signatures[\n",
        "    tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
        "    concrete_func.inputs[0].set_shape([1, 256, 256, 3])\n",
        "    concrete_func.outputs[0].set_shape([1, 256, 256, 3])\n",
        "    converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "    converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    with tf.io.gfile.GFile(tflite_model_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "    print('Fixed-point Quantized model:', tflite_model_path, \n",
        "        'Size:', len(tflite_model) / 1024, \"kb\")\n",
        "    \n",
        "convert_to_tflite('/tmp/tmp22_x9l4i/', 'selfie2anime.tflite') # Note that the path might change since we are using `tempfile`\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}